
from flask import Flask, render_template, request
import cv2
import mediapipe as mp
import numpy as np
from PIL import ImageFont, ImageDraw, Image
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()

app = Flask(__name__)
face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1)
mp_drawing = mp.solutions.drawing_utils

client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

def get_point(landmarks, index, w, h):
    lm = landmarks.landmark[index]
    return int(lm.x * w), int(lm.y * h)

def draw_text_on_image(img_path, text, output_path='static/with_text.jpg'):
    font_path = "./static/NanumGothic.ttf"
    font = ImageFont.truetype(font_path, 20)
    cv_img = cv2.imread(img_path)
    pil_img = Image.fromarray(cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(pil_img)

    lines = text.split('\n')
    x, y = 20, 20
    for line in lines:
        draw.text((x, y), line, font=font, fill=(255, 0, 0))
        y += 30

    result_img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
    cv2.imwrite(output_path, result_img)
    return output_path

def refine_with_gpt(messages: list):
    prompt = (
        "ë‹¹ì‹ ì€ ê´€ìƒ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì–¼êµ´ íŠ¹ì§•ì„ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì‹ ë¢°ê° ìˆëŠ” ë§íˆ¬ë¡œ ê´€ìƒ ë¶„ì„ì„ í•´ì£¼ì„¸ìš”.\n"
        "ë¬¸ì¥ì€ 3~4ê°œë¡œ êµ¬ì„±í•˜ë©°, ê°ê°ì˜ íŠ¹ì§•ì´ ì˜ ë“œëŸ¬ë‚˜ë„ë¡ í•´ì£¼ì„¸ìš”.\n\n"
    )

    for line in messages:
        prompt += f"- {line}\n"

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    return response.choices[0].message.content.strip()

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload():
    file = request.files['image']
    filepath = 'static/result.jpg'
    file.save(filepath)

    image = cv2.imread(filepath)
    image = cv2.resize(image, (640, 480))
    h, w, _ = image.shape
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(rgb_image)

    results_text, extended_results = [], []

    if results.multi_face_landmarks:
        for landmarks in results.multi_face_landmarks:
            jaw_left = get_point(landmarks, 234, w, h)
            jaw_right = get_point(landmarks, 454, w, h)
            chin = get_point(landmarks, 152, w, h)
            forehead = get_point(landmarks, 10, w, h)
            nose_tip = get_point(landmarks, 1, w, h)
            nose_top = get_point(landmarks, 6, w, h)
            eye_left = get_point(landmarks, 33, w, h)
            eye_right = get_point(landmarks, 263, w, h)
            eye_inner_left = get_point(landmarks, 133, w, h)
            mouth_left = get_point(landmarks, 61, w, h)
            mouth_right = get_point(landmarks, 291, w, h)

            def euclidean(p1, p2):
                return int(((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)**0.5)

            jaw_width = euclidean(jaw_left, jaw_right)
            face_height = euclidean(forehead, chin)
            eye_gap = abs(eye_left[0] - eye_right[0])
            nose_length = abs(nose_top[1] - nose_tip[1])
            mouth_slope = mouth_right[1] - mouth_left[1]
            eye_slope = eye_inner_left[1] - eye_left[1]

            if jaw_width > 270:
                results_text.append("ğŸ’ª í„±ì´ ë„“ì€ í¸ì´ë¼ ë¦¬ë”ì‹­ê³¼ ì¶”ì§„ë ¥ì´ ê°•í•©ë‹ˆë‹¤.")
            elif jaw_width < 220:
                results_text.append("ğŸ˜Š í„±ì´ ê°¸ë¦„í•´ ê°ìˆ˜ì„±ì´ í’ë¶€í•˜ê³  ì„¬ì„¸í•œ ì„±í–¥ì…ë‹ˆë‹¤.")
            else:
                results_text.append("ğŸ™‚ ê· í˜• ì¡íŒ í„±ì„ ìœ¼ë¡œ ì¡°í™”ë¡œìš´ ì„±ê²©ì…ë‹ˆë‹¤.")

            if face_height > 330:
                results_text.append("ğŸ§  ì–¼êµ´ì´ ê¸´ í¸ìœ¼ë¡œ ì‚¬ê³  ì¤‘ì‹¬ì˜ ì´ì„±ì ì¸ ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤.")
            else:
                results_text.append("ğŸ˜„ ì–¼êµ´ì´ ì§§ì€ í¸ìœ¼ë¡œ í–‰ë™ë ¥ê³¼ ì¹œê·¼í•¨ì´ ë‹ë³´ì…ë‹ˆë‹¤.")

            if eye_gap > 150:
                results_text.append("ğŸ‘€ ëˆˆ ì‚¬ì´ê°€ ë„“ì–´ ë…ë¦½ì ì´ê³  ë¶„ì„ì ì¸ ì„±ê²©ì…ë‹ˆë‹¤.")
            else:
                results_text.append("ğŸ‘€ ëˆˆ ì‚¬ì´ê°€ ê°€ê¹Œì›Œ ê°ì„±ì ì´ê³  ì‚¬ëŒ ì¤‘ì‹¬ì ì¸ ì„±í–¥ì…ë‹ˆë‹¤.")

            if nose_length > 40:
                results_text.append("ğŸ‘ƒ ì½§ëŒ€ê°€ ë†’ê³  ê¸¸ì–´ ìì¡´ê°ê³¼ ìê¸° í†µì œë ¥ì´ ë›°ì–´ë‚©ë‹ˆë‹¤.")
            else:
                results_text.append("ğŸ‘ƒ ì½§ëŒ€ê°€ ì§§ì€ í¸ì´ë¼ ìœ ì—°í•˜ê³  í¬ìš©ë ¥ì´ ê°•í•œ ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤.")

            if eye_slope < -5:
                extended_results.append("ğŸ‘ ëˆˆê¼¬ë¦¬ê°€ ì˜¬ë¼ê°€ í™œê¸°ì°¨ê³  ì™¸í–¥ì ì¸ ì„±ê²©ì…ë‹ˆë‹¤.")
            elif eye_slope > 5:
                extended_results.append("ğŸ‘ ëˆˆê¼¬ë¦¬ê°€ ë‚´ë ¤ê°€ ì°¨ë¶„í•˜ê³  ì˜¨í™”í•œ ì„±í–¥ì…ë‹ˆë‹¤.")
            else:
                extended_results.append("ğŸ‘ ëˆˆê¼¬ë¦¬ê°€ ìˆ˜í‰ì´ë¼ ì¹¨ì°©í•˜ê³  ê· í˜• ì¡íŒ ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤.")

            if mouth_slope < -5:
                extended_results.append("ğŸ˜Š ì…ê¼¬ë¦¬ê°€ ì˜¬ë¼ê°€ ë°ê³  ê¸ì •ì ì¸ ì‚¬ëŒì…ë‹ˆë‹¤.")
            elif mouth_slope > 5:
                extended_results.append("ğŸ˜ ì…ê¼¬ë¦¬ê°€ ë‚´ë ¤ê°€ ì¡°ìš©í•˜ê³  ì‹ ì¤‘í•œ ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤.")
            else:
                extended_results.append("ğŸ™‚ ì…ê¼¬ë¦¬ê°€ í‰í‰í•´ ì°¨ë¶„í•˜ê³  ë¯¿ìŒì§í•œ ì¸ìƒì„ ì¤ë‹ˆë‹¤.")

    refined_text = refine_with_gpt(results_text + extended_results)
    draw_text_on_image(filepath, refined_text)
    return render_template('index.html', filename='with_text.jpg', final_analysis=refined_text)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
