
from flask import Flask, render_template, request
import cv2
import mediapipe as mp
import numpy as np
from PIL import ImageFont, ImageDraw, Image
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°

app = Flask(__name__)
face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1)
mp_drawing = mp.solutions.drawing_utils

client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

def get_point(landmarks, index, w, h):
    lm = landmarks.landmark[index]
    return int(lm.x * w), int(lm.y * h)

def draw_text_on_image(img_path, text, output_path='static/with_text.jpg'):
    font_path = "./static/NanumGothic.ttf"
    font = ImageFont.truetype(font_path, 20)
    cv_img = cv2.imread(img_path)
    pil_img = Image.fromarray(cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(pil_img)

    lines = text.split('\n')
    x, y = 20, 20
    for line in lines:
        draw.text((x, y), line, font=font, fill=(255, 0, 0))
        y += 30

    result_img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
    cv2.imwrite(output_path, result_img)
    return output_path

def refine_with_gpt(messages: list):
    prompt = "ë‹¤ìŒì€ ì–¼êµ´ì„ ë¶„ì„í•œ ê´€ìƒ ê²°ê³¼ì•¼. ìì—°ìŠ¤ëŸ½ê³  ë§¤ë„ëŸ¬ìš´ ë§íˆ¬ë¡œ ìš”ì•½í•´ì¤˜:\n\n"
    for line in messages:
        prompt += f"- {line}\n"

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    return response.choices[0].message.content.strip()

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload():
    file = request.files['image']
    filepath = 'static/result.jpg'
    file.save(filepath)

    image = cv2.imread(filepath)
    h, w, _ = image.shape
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(rgb_image)

    results_text, extended_results = [], []

    if results.multi_face_landmarks:
        for landmarks in results.multi_face_landmarks:
            forehead_y = get_point(landmarks, 10, w, h)[1]
            nose_y = get_point(landmarks, 1, w, h)[1]
            left_eye = get_point(landmarks, 33, w, h)
            right_eye = get_point(landmarks, 263, w, h)
            eye_gap = abs(right_eye[0] - left_eye[0])
            eye_width = abs(get_point(landmarks, 133, w, h)[0] - left_eye[0])
            jaw_width = abs(get_point(landmarks, 234, w, h)[0] - get_point(landmarks, 454, w, h)[0])

            if forehead_y < nose_y - 40:
                results_text.append("ğŸ§  ì´ë§ˆê°€ ë†’ê³  ë„“ì–´ ë¦¬ë”ì‹­ê³¼ íŒë‹¨ë ¥ì´ ë›°ì–´ë‚©ë‹ˆë‹¤.")
            else:
                results_text.append("ğŸ¤” ì´ë§ˆê°€ ë‚®ì€ í¸ì´ë¼ ì‹¤ìš©ì ì´ê³  í–‰ë™ ì¤‘ì‹¬ì ì¸ ì„±í–¥ì…ë‹ˆë‹¤.")

            if eye_gap > eye_width * 1.5:
                results_text.append("ğŸ‘€ ëˆˆ ì‚¬ì´ê°€ ë„“ì–´ ë…ë¦½ì ì´ê³  ìê¸° ì£¼ì¥ì´ ê°•í•œ í¸ì…ë‹ˆë‹¤.")
            else:
                results_text.append("ğŸ‘€ ëˆˆ ì‚¬ì´ê°€ ì ë‹¹í•´ ì¡°í™”ë¡œìš´ ëŒ€ì¸ ê´€ê³„ë¥¼ ì˜ ë§ºìŠµë‹ˆë‹¤.")

            if jaw_width > w * 0.5:
                results_text.append("ğŸ’ª í„±ì´ ê°ì§€ê³  ë„“ì€ í¸ì´ë¼ ì±…ì„ê°ì´ ê°•í•œ ì„±ê²©ì…ë‹ˆë‹¤.")
            else:
                results_text.append("ğŸ˜Š í„±ì´ ê°¸ë¦„í•œ í¸ì´ë¼ ê°ì„±ì ì´ê³  ì„¬ì„¸í•œ ì„±í–¥ì…ë‹ˆë‹¤.")

            left_eye_start = get_point(landmarks, 33, w, h)
            left_eye_end = get_point(landmarks, 133, w, h)
            mouth_left = get_point(landmarks, 61, w, h)
            mouth_right = get_point(landmarks, 291, w, h)
            nose_top = get_point(landmarks, 6, w, h)
            nose_tip = get_point(landmarks, 1, w, h)

            if left_eye_end[1] < left_eye_start[1] - 5:
                extended_results.append("ğŸ‘ ëˆˆê¼¬ë¦¬ê°€ ì˜¬ë¼ê°€ ìˆì–´ í™œë°œí•˜ê³  ë‚™ì²œì ì¸ ì„±ê²©ì…ë‹ˆë‹¤.")
            elif left_eye_end[1] > left_eye_start[1] + 5:
                extended_results.append("ğŸ‘ ëˆˆê¼¬ë¦¬ê°€ ë‚´ë ¤ê°€ ìˆì–´ ì˜¨ìˆœí•˜ê³  ì°¨ë¶„í•œ ì¸ìƒì…ë‹ˆë‹¤.")
            else:
                extended_results.append("ğŸ‘ ëˆˆê¼¬ë¦¬ê°€ ìˆ˜í‰ìœ¼ë¡œ ê· í˜• ì¡íŒ ì¸ìƒì…ë‹ˆë‹¤.")

            if mouth_right[1] < mouth_left[1] - 5:
                extended_results.append("ğŸ˜Š ì…ê¼¬ë¦¬ê°€ ì˜¬ë¼ê°€ ë°ê³  ê¸ì •ì ì¸ ì„±í–¥ì…ë‹ˆë‹¤.")
            elif mouth_right[1] > mouth_left[1] + 5:
                extended_results.append("ğŸ˜ ì…ê¼¬ë¦¬ê°€ ì‚´ì§ ë‚´ë ¤ê°€ ì¡°ìš©í•˜ê³  ì‹ ì¤‘í•œ ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤.")
            else:
                extended_results.append("ğŸ™‚ ì…ê¼¬ë¦¬ê°€ ì¤‘ë¦½ì ì´ë©° ì°¨ë¶„í•œ ì„±ê²©ì…ë‹ˆë‹¤.")

            if nose_top[1] < nose_tip[1] - 20:
                extended_results.append("ğŸ‘ƒ ì½§ëŒ€ê°€ ë†’ì•„ ìì¡´ê°ê³¼ ìì‹ ê°ì´ ê°•í•œ ì„±í–¥ì…ë‹ˆë‹¤.")
            else:
                extended_results.append("ğŸ‘ƒ ì½§ëŒ€ê°€ ë‚®ì•„ ê²¸ì†í•˜ê³  ì¡°í™”ë¡œìš´ ì„±ê²©ì…ë‹ˆë‹¤.")

    refined_text = refine_with_gpt(results_text + extended_results)
    draw_text_on_image(filepath, refined_text)
    return render_template('index.html', filename='with_text.jpg', final_analysis=refined_text)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
